# -*- coding: utf-8 -*-
"""Foto3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tqCPliiNw-EBc6VX3RW3v8peATdxJw3g
"""

# 📦 1) installa le dipendenze (solo la prima volta)
#!pip install -q opencv-python pillow ipywidgets

# 🔧 2) moduli
import cv2, math, base64, io
import numpy as np
import ipywidgets as widgets
from google.colab import files
from PIL import Image
from IPython.display import display, clear_output, HTML

# ╭────────────────────────────────────────────────────────────╮
# │  LOOK-UP TABLES  ORANGE & TEAL MORBIDE                     │
# ╰────────────────────────────────────────────────────────────╯
def build_orange_teal_LUT(
        sigma_h        = 15,   # campana un po' più larga → transizioni extra-dolci
        warm_h         = 15,   # centro arancione
        cool_h         = 90,   # centro teal
        sat_boost_warm = 1.45,
        sat_boost_cool = 1.20
    ):
    hue_lut = np.zeros(180, np.uint8)
    sat_lut = np.ones(180,  np.float32)
    two_sigma2 = 2.0 * sigma_h**2

    for h in range(180):
        dw = min(abs(h - warm_h), 180 - abs(h - warm_h))
        dc = min(abs(h - cool_h), 180 - abs(h - cool_h))

        w_warm = math.exp(-(dw**2) / two_sigma2)
        w_cool = math.exp(-(dc**2) / two_sigma2)

        if w_warm + w_cool < 1e-6:             # zona neutra
            hue_lut[h] = h
            sat_lut[h] = 1.0
        else:
            w_sum  = w_warm + w_cool
            w_warm /= w_sum
            w_cool  = 1.0 - w_warm

            hue_lut[h] = np.uint8(round(w_warm*warm_h + w_cool*cool_h)) % 180
            sat_lut[h] = w_warm*sat_boost_warm + w_cool*sat_boost_cool

    return hue_lut, sat_lut

# LUT globale
_HUE_LUT, _SAT_LUT = build_orange_teal_LUT()

# ╭────────────────────────────────────────╮
# │  CURVA CONTRASTO MORBIDA (smooth-step) │
# ╰────────────────────────────────────────╯
def _smooth_contrast(v: np.ndarray,
                     mid_boost  = 1.05,
                     shadow_mul = 0.93,
                     hi_mul     = 1.06) -> np.ndarray:
    """
    Sostituisce i vecchi tagli netti con un'unica curva continua:
        •  shadow_mul   a V=0
        •  mid_boost    al centro (V≈128)
        •  hi_mul       a V=255
    La “smooth-step” (3t²-2t³) garantisce derivata nulla agli estremi → niente banding.
    """
    v_f = v.astype(np.float32)
    t   = v_f / 255.0                         # normalizzato 0-1
    smooth = t*t*(3.0 - 2.0*t)               # smooth-step
    boost  = shadow_mul + (hi_mul - shadow_mul)*smooth
    v_new  = v_f * boost * mid_boost
    return np.clip(v_new, 0, 255).astype(np.uint8)

# ╭────────────────────────────────────────╮
# │  FILTRO ORANGE-&-TEAL “GRADUAL”        │
# ╰────────────────────────────────────────╯
def apply_orange_teal_gradual(bgr_img: np.ndarray) -> np.ndarray:
    hsv = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv)

    # tonalità (lookup diretto super-veloce)
    h = _HUE_LUT[h]

    # saturazione
    sat_mult = _SAT_LUT[h]
    s = np.clip(s.astype(np.float32) * sat_mult, 0, 255).astype(np.uint8)

    # value – curva morbida
    v = _smooth_contrast(v)

    hsv_new = cv2.merge([h, s, v])
    return cv2.cvtColor(hsv_new, cv2.COLOR_HSV2BGR)

# ╭────────────────────────────────────────╮
# │  FILTRI MONO DOMINANTE (come prima)    │
# ╰────────────────────────────────────────╯
def _build_monotone_LUT(target_h, sat_boost):
    hue = np.full(180, target_h, np.uint8)
    sat = np.full(180, sat_boost, np.float32)
    return hue, sat

_HUE_ORANGE, _SAT_ORANGE = _build_monotone_LUT(15, 1.60)
_HUE_TEAL,   _SAT_TEAL   = _build_monotone_LUT(90, 1.30)

def _apply_monotone(bgr_img, hue_lut, sat_lut):
    hsv  = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv)
    h = hue_lut[h]
    s = np.clip(s.astype(np.float32) * sat_lut[h], 0, 255).astype(np.uint8)
    v = _smooth_contrast(v)
    return cv2.cvtColor(cv2.merge([h, s, v]), cv2.COLOR_HSV2BGR)

def apply_all_orange(img): return _apply_monotone(img, _HUE_ORANGE, _SAT_ORANGE)
def apply_all_teal(img):   return _apply_monotone(img, _HUE_TEAL,   _SAT_TEAL)

# ╭────────────────────────────────────────╮
# │  UTIL DI VISUALIZZAZIONE               │
# ╰────────────────────────────────────────╯
def display_cv_image(img_bgr, title=""):
    rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
    pil = Image.fromarray(rgb)
    buf = io.BytesIO(); pil.save(buf, format="JPEG")
    img64 = base64.b64encode(buf.getvalue()).decode()
    html  = f"<h4 style='margin:4px 0'>{title}</h4>" \
            f"<img src='data:image/jpeg;base64,{img64}' " \
            f"style='max-width:400px;margin:6px 0'/>"
    display(HTML(html))

# ╭────────────────────────────────────────╮
# │  INTERFACCIA COLAB                     │
# ╰────────────────────────────────────────╯
btn_upload   = widgets.Button(description="📤 Carica immagine")
out_ot, out_orange, out_teal = "orange_teal_output.jpg", "all_orange_output.jpg", "all_teal_output.jpg"
btn_dl_ot     = widgets.Button(description=f"📥 Scarica O&T ({out_ot})", disabled=True)
btn_dl_orange = widgets.Button(description=f"📥 Scarica Arancione ({out_orange})", disabled=True)
btn_dl_teal   = widgets.Button(description=f"📥 Scarica Turchese ({out_teal})", disabled=True)

uploaded_img = None

def on_upload_clicked(_):
    global uploaded_img
    clear_output(wait=True)
    display(btn_upload)
    print("Seleziona il file…")
    up = files.upload()
    if not up:
        for b in (btn_dl_ot, btn_dl_orange, btn_dl_teal): b.disabled = True
        display(widgets.HBox([btn_dl_ot, btn_dl_orange, btn_dl_teal])); return

    fname = next(iter(up))
    data  = np.frombuffer(up[fname], np.uint8)
    uploaded_img = cv2.imdecode(data, cv2.IMREAD_COLOR)

    if uploaded_img is None:
        print("Errore nel caricamento.")
        for b in (btn_dl_ot, btn_dl_orange, btn_dl_teal): b.disabled = True
        display(widgets.HBox([btn_dl_ot, btn_dl_orange, btn_dl_teal])); return

    print("Applicazione filtri…")
    img_ot     = apply_orange_teal_gradual(uploaded_img.copy())
    img_orange = apply_all_orange(uploaded_img.copy())
    img_teal   = apply_all_teal(uploaded_img.copy())

    cv2.imwrite(out_ot,     img_ot)
    cv2.imwrite(out_orange, img_orange)
    cv2.imwrite(out_teal,   img_teal)

    print("Anteprime:")
    display_cv_image(uploaded_img, "Originale")
    display_cv_image(img_ot,     "Orange & Teal (sfumato)")
    display_cv_image(img_orange, "Dominante Arancione")
    display_cv_image(img_teal,   "Dominante Turchese / Azzurro")

    for b in (btn_dl_ot, btn_dl_orange, btn_dl_teal): b.disabled = False
    print("Pronto! Usa i pulsanti per scaricare le versioni filtrate.")
    display(widgets.HBox([btn_dl_ot, btn_dl_orange, btn_dl_teal]))

def on_download(_, path): files.download(path)
btn_upload.on_click(on_upload_clicked)
btn_dl_ot.on_click(lambda b: on_download(b, out_ot))
btn_dl_orange.on_click(lambda b: on_download(b, out_orange))
btn_dl_teal.on_click(lambda b: on_download(b, out_teal))

# prima vista
display(btn_upload)
display(widgets.HBox([btn_dl_ot, btn_dl_orange, btn_dl_teal]))

"""# Spiegazione Codice

Questo codice Python implementa un filtro "Orange & Teal" per le immagini, un effetto popolare nel cinema e nella fotografia che spinge i colori caldi verso l'arancione e i colori freddi verso il turchese (teal), creando un look stilizzato e con un buon contrasto cromatico.

Analizziamo il codice sezione per sezione:

---

### 📦 1) Installazione dipendenze (solo la prima volta)
```python
!pip install -q opencv-python pillow ipywidgets
```
Questa riga installa le librerie necessarie se non sono già presenti nell'ambiente.
* `opencv-python`: Libreria fondamentale per l'elaborazione di immagini e video (lettura, manipolazione, salvataggio).
* `pillow`: Altra libreria per la manipolazione di immagini, spesso usata in congiunzione o come dipendenza di altre.
* `ipywidgets`: Permette di creare elementi interattivi (come pulsanti) negli ambienti Jupyter Notebook o Google Colab.

---

### 🔧 2) Moduli
```python
import cv2, math, base64, io
import numpy as np
import ipywidgets as widgets
from google.colab import files
from PIL import Image
from IPython.display import display, clear_output, HTML
```
Qui vengono importati i moduli (librerie) che contengono le funzioni e le classi utilizzate nel resto dello script.
* `cv2`: OpenCV.
* `math`: Funzioni matematiche (es. `exp` per l'esponenziale).
* `base64`, `io`: Usati per codificare/decodificare immagini per la visualizzazione diretta in HTML.
* `numpy` (alias `np`): Essenziale per lavorare con array numerici, che è come le immagini vengono rappresentate (matrici di pixel).
* `ipywidgets` (alias `widgets`): Per i controlli dell'interfaccia utente.
* `google.colab.files`: Specifico per Google Colab, per caricare e scaricare file.
* `PIL.Image`: Da Pillow, per creare e manipolare oggetti immagine.
* `IPython.display`: Per visualizzare output formattato (come HTML) e pulire l'output della cella in Colab/Jupyter.

---

### ╭────────────────────────────────────────────────────────────╮
### │  LOOK-UP TABLES  ORANGE & TEAL MORBIDE                     │
### ╰────────────────────────────────────────────────────────────╯
```python
def build_orange_teal_LUT(
        sigma_h        = 15,
        warm_h         = 15,
        cool_h         = 90,
        sat_boost_warm = 1.45,
        sat_boost_cool = 1.20
    ):
    # ... (corpo della funzione) ...
    return hue_lut, sat_lut

_HUE_LUT, _SAT_LUT = build_orange_teal_LUT()
```
Questa è una delle parti cruciali.
* **Concetto di LUT (Look-Up Table)**: Una LUT è una tabella precalcolata. Invece di calcolare una trasformazione complessa per ogni pixel di un'immagine ogni volta, si precalcolano i risultati per tutti i possibili valori di input (in questo caso, le tonalità da 0 a 179) e li si memorizza. Durante l'applicazione del filtro, si "cerca" semplicemente il valore trasformato nella tabella, rendendo il processo molto più veloce.
* **`build_orange_teal_LUT`**: Questa funzione crea due LUT:
    * `hue_lut`: Mappa ogni tonalità (Hue) originale a una nuova tonalità.
    * `sat_lut`: Definisce un moltiplicatore per la saturazione (Saturation) per ogni tonalità originale.
* **Parametri**:
    * `sigma_h`: Controlla la "larghezza" della campana gaussiana, determinando quanto dolcemente avviene la transizione dei colori verso l'arancione o il turchese. Un valore più alto significa transizioni più morbide e ampie.
    * `warm_h`: La tonalità target per i colori caldi (arancione, tipicamente intorno a 15-30 nello spazio colore HSV di OpenCV dove H va da 0 a 179).
    * `cool_h`: La tonalità target per i colori freddi (turchese/teal, tipicamente intorno a 90-100).
    * `sat_boost_warm`/`cool`: Fattori di quanto aumentare la saturazione per i colori che virano verso l'arancione o il turchese.
* **Logica interna**:
    1.  Per ogni possibile tonalità di input `h` (da 0 a 179):
    2.  Calcola la "distanza" di `h` da `warm_h` e `cool_h` (tenendo conto della natura circolare della tonalità).
    3.  Usa una **funzione gaussiana** (`math.exp(-(dw**2) / two_sigma2)`) per calcolare dei "pesi" (`w_warm`, `w_cool`). Più una tonalità è vicina a `warm_h`, maggiore sarà `w_warm`, e viceversa per `cool_h`. `sigma_h` determina quanto rapidamente questi pesi diminuiscono con la distanza.
    4.  Se una tonalità è lontana da entrambe (zona neutra), la sua tonalità e saturazione rimangono invariate.
    5.  Altrimenti, la nuova tonalità è una **media pesata** di `warm_h` e `cool_h`, e il nuovo moltiplicatore di saturazione è una media pesata di `sat_boost_warm` e `sat_boost_cool`. Questo crea la transizione morbida: i colori non saltano bruscamente ad arancione o turchese, ma ci si avvicinano gradualmente.
* `_HUE_LUT, _SAT_LUT = build_orange_teal_LUT()`: Crea le LUT globali una volta all'inizio con i parametri di default.

---

### ╭────────────────────────────────────────╮
### │  CURVA CONTRASTO MORBIDA (smooth-step) │
### ╰────────────────────────────────────────╯
```python
def _smooth_contrast(v: np.ndarray,
                     mid_boost  = 1.05,
                     shadow_mul = 0.93,
                     hi_mul     = 1.06) -> np.ndarray:
    # ... (corpo della funzione) ...
    return np.clip(v_new, 0, 255).astype(np.uint8)
```
Questa funzione applica una curva di contrasto non lineare al canale della Luminosità (Value) dell'immagine.
* **Scopo**: Migliorare il contrasto in modo "morbido", scurendo leggermente le ombre, aumentando leggermente i mezzitoni e schiarendo leggermente le alte luci, senza creare artefatti come il "banding" (scalettature visibili nelle sfumature).
* **`smooth-step`**: La formula `t*t*(3.0 - 2.0*t)` (dove `t` è il valore normalizzato tra 0 e 1) è una funzione di interpolazione S-curva (sigmoide) che ha derivate nulle agli estremi (0 e 1). Questo garantisce che le transizioni ai neri puri e ai bianchi puri siano molto graduali, evitando appunto il banding.
* **Parametri**:
    * `mid_boost`: Moltiplicatore per i mezzitoni.
    * `shadow_mul`: Moltiplicatore per le ombre (valori < 1 scuriscono).
    * `hi_mul`: Moltiplicatore per le alte luci (valori > 1 schiariscono).
* **Logica**: Applica questa curva S per modificare i valori di luminosità dei pixel.

---

### ╭────────────────────────────────────────╮
### │  FILTRO ORANGE-&-TEAL “GRADUAL”        │
### ╰────────────────────────────────────────╯
```python
def apply_orange_teal_gradual(bgr_img: np.ndarray) -> np.ndarray:
    hsv = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv)

    h = _HUE_LUT[h] # Applica LUT tonalità
    sat_mult = _SAT_LUT[h] # Ottiene moltiplicatore saturazione DALLA NUOVA TONALITÀ
    s = np.clip(s.astype(np.float32) * sat_mult, 0, 255).astype(np.uint8) # Applica moltiplicatore saturazione
    v = _smooth_contrast(v) # Applica curva di contrasto

    hsv_new = cv2.merge([h, s, v])
    return cv2.cvtColor(hsv_new, cv2.COLOR_HSV2BGR)
```
Questa è la funzione principale che applica il filtro Orange & Teal.
1.  **Conversione a HSV**: L'immagine viene convertita dallo spazio colore BGR (Blu, Verde, Rosso - default di OpenCV) a HSV (Hue, Saturation, Value - Tonalità, Saturazione, Valore/Luminosità). Lavorare in HSV è più intuitivo per modifiche cromatiche perché separa la tonalità del colore dalla sua intensità e luminosità.
2.  **Separazione canali**: I canali H, S, V vengono separati.
3.  **Applicazione LUT Tonalità**: `h = _HUE_LUT[h]` sostituisce ogni valore di tonalità originale con il nuovo valore precalcolato dalla `_HUE_LUT`. Questa è un'operazione vettorizzata molto veloce di NumPy.
4.  **Applicazione LUT Saturazione**:
    * `sat_mult = _SAT_LUT[h]`: È importante notare che il moltiplicatore di saturazione viene preso dalla `_SAT_LUT` usando la **nuova tonalità** (quella modificata al passo precedente). Questo significa che la saturazione viene potenziata in base a *quale colore diventerà* il pixel, non al suo colore originale.
    * La saturazione originale `s` viene moltiplicata per `sat_mult` e poi "clippata" (limitata) all'intervallo 0-255.
5.  **Applicazione Contrasto**: La funzione `_smooth_contrast` viene applicata al canale `v` (Luminosità).
6.  **Unione canali e Riconversione**: I canali H, S, V modificati vengono riuniti e l'immagine HSV viene riconvertita in BGR per poterla visualizzare o salvare correttamente.

---

### ╭────────────────────────────────────────╮
### │  FILTRI MONO DOMINANTE (come prima)    │
### ╰────────────────────────────────────────╯
```python
def _build_monotone_LUT(target_h, sat_boost):
    # ...
def _apply_monotone(bgr_img, hue_lut, sat_lut):
    # ...
def apply_all_orange(img): return _apply_monotone(img, _HUE_ORANGE, _SAT_ORANGE)
def apply_all_teal(img):   return _apply_monotone(img, _HUE_TEAL,   _SAT_TEAL)
```
Queste funzioni creano filtri più semplici che danno all'intera immagine una dominante di colore unica (o tutta arancione o tutta turchese).
* `_build_monotone_LUT`: Crea delle LUT molto semplici dove **tutte** le tonalità di input vengono mappate a una singola `target_h` e a un `sat_boost` uniforme.
* `_apply_monotone`: Applica queste LUT monotone e la stessa curva di contrasto `_smooth_contrast` del filtro principale.
* `apply_all_orange` / `apply_all_teal`: Funzioni di comodo che preimpostano le LUT per una dominante arancione o turchese.

---

### ╭────────────────────────────────────────╮
### │  UTIL DI VISUALIZZAZIONE               │
### ╰────────────────────────────────────────╯
```python
def display_cv_image(img_bgr, title=""):
    # ...
```
Questa funzione serve a visualizzare un'immagine OpenCV (in formato BGR) direttamente nell'output di una cella Colab/Jupyter.
1.  Converte l'immagine da BGR a RGB (necessario per la maggior parte dei sistemi di visualizzazione).
2.  La converte in un oggetto `Image` di Pillow.
3.  Salva l'immagine in un buffer di memoria in formato JPEG.
4.  Codifica i dati dell'immagine in Base64.
5.  Crea una stringa HTML che include un tag `<img>` con i dati dell'immagine Base64 incorporati. Questo permette di mostrare l'immagine senza doverla prima salvare su disco.

---

### ╭────────────────────────────────────────╮
### │  INTERFACCIA COLAB                     │
### ╰────────────────────────────────────────╯
```python
btn_upload   = widgets.Button(description="📤 Carica immagine")
# ... (definizione altri bottoni) ...

uploaded_img = None

def on_upload_clicked(_):
    # ... (logica caricamento e applicazione filtri) ...

def on_download(_, path): files.download(path)
# ... (collegamento eventi ai bottoni) ...

# prima vista
display(btn_upload)
# ...
```
Questa sezione crea un'interfaccia utente semplice in Google Colab:
* **Pulsanti**: Vengono creati pulsanti (`widgets.Button`) per:
    * Caricare un'immagine (`btn_upload`).
    * Scaricare le versioni filtrate dell'immagine (O&T, Arancione, Turchese).
* **`on_upload_clicked`**: Questa funzione viene eseguita quando si clicca il pulsante di upload.
    1.  Pulisce l'output precedente.
    2.  Usa `files.upload()` per far selezionare un file all'utente.
    3.  Legge i dati dell'immagine caricata e la decodifica con OpenCV (`cv2.imdecode`).
    4.  Se il caricamento ha successo, applica i tre filtri (`apply_orange_teal_gradual`, `apply_all_orange`, `apply_all_teal`) a copie dell'immagine originale.
    5.  Salva le immagini filtrate su disco nell'ambiente Colab (`cv2.imwrite`).
    6.  Visualizza le anteprime dell'originale e delle immagini filtrate usando `display_cv_image`.
    7.  Abilita i pulsanti di download.
* **`on_download`**: Funzione chiamata quando si clicca un pulsante di download, usa `files.download(path)` per avviare il download del file specificato dal browser.
* **Collegamento eventi**: `btn_upload.on_click(...)` associa le funzioni definite ai click dei rispettivi pulsanti.
* **Visualizzazione iniziale**: Mostra il pulsante di upload e i pulsanti di download (inizialmente disabilitati).

In sintesi, il codice definisce le trasformazioni di colore e contrasto (principalmente attraverso LUT e curve smooth-step), le applica alle immagini e fornisce un'interfaccia utente basilare per caricare, processare e scaricare le immagini in un ambiente Colab. L'approccio con le LUT è efficiente, e la separazione in HSV permette un controllo mirato degli aspetti cromatici.

# Modifiche dei colori

Esatto, hai colto il punto se il tuo interesse è **modificare l'effetto dei filtri che applicano una dominante di colore unica** (quelli che prima erano `apply_all_orange` e `apply_all_teal`).

Per essere precisi:

1.  **Per i filtri monocromatici (es. "tutto rosso" o "tutto verde"):**
    Le righe che definiscono le LUT per questi filtri sono:
    ```python
    _HUE_ORANGE, _SAT_ORANGE = _build_monotone_LUT(15, 1.60) # Per il primo colore dominante
    _HUE_TEAL,   _SAT_TEAL   = _build_monotone_LUT(90, 1.30) # Per il secondo colore dominante
    ```
    Se vuoi cambiare, per esempio, l'arancione in rosso e il turchese in verde per questi filtri specifici:
    * Al posto di `15` (tonalità arancione), metteresti il valore di tonalità (Hue, nello spazio colore HSV di OpenCV, tipicamente 0-179) per il **rosso** (es. `5` o `0`).
    * Al posto di `90` (tonalità teal/turchese), metteresti il valore di tonalità per il **verde** (es. `60`).

    Quindi sì, modificheresti il primo argomento `X` (la tonalità target) in queste due righe:
    ```python
    _HUE_COLORE1, _SAT_COLORE1 = _build_monotone_LUT(VALORE_HUE_COLORE_1, 1.60)
    _HUE_COLORE2, _SAT_COLORE2 = _build_monotone_LUT(VALORE_HUE_COLORE_2, 1.30)
    ```
    Questo cambierà il comportamento delle funzioni `apply_all_orange` e `apply_all_teal` (che a questo punto mentalmente o nel codice potresti chiamare `apply_all_rosso` e `apply_all_verde`).

2.  **Importante: per il filtro principale "Orange & Teal graduale":**
    Se vuoi cambiare i colori anche per il filtro principale (quello chiamato `apply_orange_teal_gradual` che mappa le tonalità calde a un colore e quelle fredde a un altro in modo più sfumato), allora la modifica è leggermente diversa. Devi cambiare i parametri passati alla funzione `build_orange_teal_LUT` quando vengono create le LUT globali `_HUE_LUT` e `_SAT_LUT`:
    ```python
    # Riga originale
    # _HUE_LUT, _SAT_LUT = build_orange_teal_LUT()

    # Riga modificata per, ad esempio, Rosso e Verde
    _HUE_LUT, _SAT_LUT = build_orange_teal_LUT(
        warm_h = VALORE_HUE_PER_IL_ROSSO,  # Sostituisce 'warm_h = 15' (arancione)
        cool_h = VALORE_HUE_PER_IL_VERDE   # Sostituisce 'cool_h = 90' (teal)
        # Eventualmente puoi anche aggiustare sat_boost_warm e sat_boost_cool
    )
    ```

**In breve:**

* Se ti interessano **solo i filtri che rendono l'immagine interamente di una tonalità dominante**, allora la tua osservazione è corretta: modifichi il primo parametro nelle chiamate a `_build_monotone_LUT`.
* Se vuoi cambiare anche l'effetto del **filtro principale che combina i due colori in modo graduale**, devi modificare i parametri `warm_h` e `cool_h` nella chiamata a `build_orange_teal_LUT`.

Dato che hai menzionato specificamente `_build_monotone_LUT(X, 1.60)`, la tua comprensione per *quel tipo specifico di filtro* è corretta.

# Aggiunta colore

Sì, aggiungere un terzo colore al filtro principale (quello che prima era "Orange & Teal" e ora diventerebbe, ad esempio, "Rosso, Verde & Blu") comporterebbe modifiche più significative rispetto al semplice cambio dei due colori esistenti. Dovresti modificare la logica interna della funzione `build_orange_teal_LUT` (che a questo punto potresti voler rinominare, tipo `build_multi_color_LUT`, ma tralasciamo le etichette come hai detto).

Ecco le modifiche concettuali e pratiche necessarie, concentrandoci sulla funzione `build_orange_teal_LUT`:

1.  **Nuovi Parametri per la Funzione:**
    La funzione dovrebbe accettare parametri per il terzo colore:
    * Una terza tonalità target (es. `third_h`).
    * Un terzo boost di saturazione (es. `sat_boost_third`).

    La firma della funzione potrebbe diventare (ipotizzando di modificare l'originale):
    ```python
    def build_orange_teal_LUT( # O build_multi_color_LUT
            sigma_h        = 15,
            warm_h         = 15,   # Primo colore target
            cool_h         = 90,   # Secondo colore target
            third_h        = 150,  # TERZO colore target (es. un blu/viola)
            sat_boost_warm = 1.45, # Boost sat. primo colore
            sat_boost_cool = 1.20, # Boost sat. secondo colore
            sat_boost_third= 1.35  # Boost sat. TERZO colore
        ):
        # ...
    ```

2.  **Calcolo della Distanza e del Peso per il Terzo Colore:**
    All'interno del ciclo `for h in range(180):`, dovresti:
    * Calcolare la distanza `d_third` della tonalità corrente `h` da `third_h`.
        ```python
        # dw e dc sono già calcolati per warm_h e cool_h
        d_third = min(abs(h - third_h), 180 - abs(h - third_h))
        ```
    * Calcolare il peso `w_third` per il terzo colore, usando la stessa logica gaussiana.
        ```python
        # w_warm e w_cool sono già calcolati
        w_third = math.exp(-(d_third**2) / two_sigma2)
        ```

3.  **Normalizzazione dei Pesi:**
    Ora hai tre pesi: `w_warm`, `w_cool`, e `w_third`. Devono essere normalizzati in modo che la loro somma sia 1, per poterli usare in una media pesata.
    * Calcola la somma totale dei pesi:
        ```python
        w_sum  = w_warm + w_cool + w_third
        ```
    * Aggiorna la condizione per la "zona neutra":
        ```python
        if w_sum < 1e-6:  # Se tutti i pesi sono trascurabili
            hue_lut[h] = h
            sat_lut[h] = 1.0
        else:
            # Normalizza i pesi
            w_warm_norm  = w_warm / w_sum
            w_cool_norm  = w_cool / w_sum
            w_third_norm = w_third / w_sum # o w_third_norm = 1.0 - w_warm_norm - w_cool_norm (con attenzione agli errori di floating point)
        ```
    * **Nota:** Per garantire che la somma sia esattamente 1 e per semplicità, potresti fare:
        ```python
        # ... (calcolo w_warm, w_cool, w_third, w_sum)
        # else:
            w_warm  /= w_sum
            w_cool  /= w_sum
            # w_third /= w_sum # Non necessario se si calcola per differenza, ma più pulito per coerenza
            w_third_final = 1.0 - w_warm - w_cool # Assumendo che w_warm e w_cool siano già stati normalizzati rispetto a w_sum
                                                # Oppure, più robusto:
            # w_warm_norm = w_warm / w_sum
            # w_cool_norm = w_cool / w_sum
            # w_third_norm = w_third / w_sum # Calcola tutti e tre i pesi normalizzati
        ```
        Per chiarezza e robustezza, è meglio normalizzare tutti e tre i pesi dividendoli per `w_sum`.

4.  **Calcolo della Nuova Tonalità e Saturazione:**
    La nuova tonalità e il nuovo moltiplicatore di saturazione saranno una media pesata basata sui tre colori e i loro pesi normalizzati.
    ```python
            # ... (dopo la normalizzazione dei pesi w_warm_norm, w_cool_norm, w_third_norm)
            hue_lut[h] = np.uint8(round(w_warm_norm * warm_h + \
                                         w_cool_norm * cool_h + \
                                         w_third_norm * third_h)) % 180

            sat_lut[h] = (w_warm_norm * sat_boost_warm + \
                          w_cool_norm * sat_boost_cool + \
                          w_third_norm * sat_boost_third)
    ```

5.  **Chiamata alla Funzione Modificata:**
    Quando crei le LUT globali, dovrai passare i parametri per tutti e tre i colori:
    ```python
    _HUE_LUT, _SAT_LUT = build_orange_teal_LUT( # o build_multi_color_LUT
        warm_h=HUE_COLORE_1, sat_boost_warm=SAT_BOOST_1,
        cool_h=HUE_COLORE_2, sat_boost_cool=SAT_BOOST_2,
        third_h=HUE_COLORE_3, sat_boost_third=SAT_BOOST_3
    )
    ```

**Riepilogo delle modifiche necessarie all'interno di `build_orange_teal_LUT`:**

* Aggiungere parametri per il terzo colore alla definizione della funzione.
* Calcolare distanza e peso per il terzo colore.
* Modificare la logica di normalizzazione per includere tre pesi.
* Modificare il calcolo della nuova tonalità e saturazione per includere il contributo del terzo colore.

**Modifiche al di fuori di `build_orange_teal_LUT`:**

* Aggiornare la chiamata a questa funzione per fornire i valori per il terzo colore.

La funzione `apply_orange_teal_gradual` **non avrebbe bisogno di modifiche** perché lavora con le `_HUE_LUT` e `_SAT_LUT` precalcolate, indipendentemente da come sono state generate (con due o tre colori).

**In termini di "quante modifiche":**

* **All'interno di `build_orange_teal_LUT`**: circa 5-8 nuove righe o righe modificate significativamente per la logica di calcolo, più l'aggiunta dei nuovi parametri nella firma.
* **La chiamata alla funzione**: 1 riga modificata per includere i nuovi argomenti.

Quindi, le modifiche sono più sostanziose perché intaccano il nucleo dell'algoritmo di generazione della LUT, ma concettualmente si tratta di estendere la logica esistente da due a tre componenti. Non è un rifacimento completo, ma un'espansione mirata.
"""